!ModelConfig
config_data: !DataConfig
  data_statistics: !DataStatistics
    average_len_target_per_bucket:
    - 6.536779555828388
    - 12.695111308360453
    - 21.113829676281792
    - 29.702584587020255
    - 37.97110374449988
    - 46.07846054633612
    - 53.85288055852154
    - 61.082317040412825
    - 68.07096396771524
    - 74.83928896899513
    - 78.72540254824904
    - 81.3454750934538
    buckets:
    - !!python/tuple
      - 9
      - 10
    - !!python/tuple
      - 18
      - 20
    - !!python/tuple
      - 27
      - 30
    - !!python/tuple
      - 36
      - 40
    - !!python/tuple
      - 45
      - 50
    - !!python/tuple
      - 54
      - 60
    - !!python/tuple
      - 63
      - 70
    - !!python/tuple
      - 72
      - 80
    - !!python/tuple
      - 81
      - 90
    - !!python/tuple
      - 90
      - 100
    - !!python/tuple
      - 99
      - 100
    - !!python/tuple
      - 100
      - 100
    length_ratio_mean: 1.0645400645552539
    length_ratio_std: 0.29834278125977903
    max_observed_len_source: 100
    max_observed_len_target: 100
    num_discarded: 408226
    num_sents: 56657132
    num_sents_per_bucket:
    - 23211115
    - 18449333
    - 6644559
    - 3384680
    - 1940286
    - 1186265
    - 741384
    - 465335
    - 302562
    - 197516
    - 122594
    - 11503
    num_tokens_source: 881889667
    num_tokens_target: 869418202
    num_unks_source: 0
    num_unks_target: 0
    size_vocab_source: 15989
    size_vocab_target: 13585
  max_seq_len_source: 100
  max_seq_len_target: 100
  num_source_factors: 1
  source_with_eos: true
config_decoder: !RecurrentDecoderConfig
  attention_config: !AttentionConfig
    config_coverage: null
    dtype: float32
    input_previous_word: false
    is_scaled: false
    layer_normalization: false
    num_heads: null
    num_hidden: 1024
    query_num_hidden: 1024
    source_num_hidden: 1024
    type: dot
  attention_in_upper_layers: false
  context_gating: false
  dtype: float32
  enc_last_hidden_concat_to_embedding: false
  hidden_dropout: 0.2
  layer_normalization: false
  max_seq_len_source: 100
  rnn_config: !RNNConfig
    cell_type: lstm
    dropout_inputs: 0.0
    dropout_recurrent: 0.0
    dropout_states: 0.0
    dtype: float32
    first_residual_layer: 2
    forget_bias: 0.0
    lhuc: false
    num_hidden: 1024
    num_layers: 6
    residual: false
  state_init: last
  state_init_lhuc: false
config_embed_source: !EmbeddingConfig
  dropout: 0.0
  dtype: float32
  factor_configs: null
  num_embed: 512
  num_factors: 1
  vocab_size: 15989
config_embed_target: !EmbeddingConfig
  dropout: 0.0
  dtype: float32
  factor_configs: null
  num_embed: 512
  num_factors: 1
  vocab_size: 13585
config_encoder: !RecurrentEncoderConfig
  conv_config: null
  dtype: float32
  reverse_input: false
  rnn_config: !RNNConfig
    cell_type: lstm
    dropout_inputs: 0.0
    dropout_recurrent: 0.0
    dropout_states: 0.0
    dtype: float32
    first_residual_layer: 2
    forget_bias: 0.0
    lhuc: false
    num_hidden: 1024
    num_layers: 6
    residual: false
config_loss: !LossConfig
  label_smoothing: 0.1
  name: cross-entropy
  normalization_type: valid
  vocab_size: 13585
lhuc: false
vocab_source_size: 15989
vocab_target_size: 13585
weight_normalization: false
weight_tying: false
weight_tying_type: null
